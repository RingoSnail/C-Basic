【IO模型】

网络 - 数据到达 - 复制到内核缓冲区 - 复制到进程缓冲区

Unix 有五种 I/O 模型：

阻塞式 I/O           （recvfrom）单个进程阻塞，对于整个系统而言，CPU利用率高
非阻塞式 I/O         （recvfrom）进程不阻塞，但需要轮询(polling)，CPU利用率不高
I/O 复用             （select 和 poll）（事件驱动I/O）由select处理多个I/O，不必开多线程，开销小
信号驱动 I/O         （SIGIO）不阻塞，内核数据到达后发送SIGIO信号，再recvfrom，CPU利用率高
异步 I/O（AIO）       aio_read 进程不阻塞，拷贝也不阻塞

比较：

同步 I/O：将数据从内核缓冲区复制到应用进程缓冲区的阶段（第二阶段），应用进程会阻塞。
异步 I/O：第二阶段应用进程不会阻塞。


select/poll/epoll 都是 I/O 多路复用的具体实现

【select】 数组实现fd_set 

select 允许应用程序监视一组文件描述符，等待一个或者多个描述符成为就绪状态，从而完成 I/O 操作。

【poll】 pollfd 类型的数组 

select 会修改描述符，而 poll 不会；
select 的描述符类型使用数组实现，FD_SETSIZE 大小默认为 1024，因此默认只能监听少于 1024 个描述符。
如果要监听更多描述符的话，需要修改 FD_SETSIZE 之后重新编译；而 poll 没有描述符数量的限制；
poll 提供了更多的事件类型，并且对描述符的重复利用上比 select 高。
如果一个线程对某个描述符调用了 select 或者 poll，另一个线程关闭了该描述符，会导致调用结果不确定。

select 和 poll 速度都比较慢，每次调用都需要将全部描述符从应用进程缓冲区复制到内核缓冲区

【epoll】
epoll_create(int size)
epoll_ctl(int epfd， int op， int fd， struct epoll_event *event)注册或改变某个文件描述符的状态
int epoll_wait(int epfd， struct epoll_event *events， int maxevents， int timeout)

已注册的描述符在内核中会被维护在一棵【红黑树】上，
通过回调函数内核会将 I/O 准备好的描述符加入到一个【链表】中管理，
进程调用 epoll_wait() 便可以得到事件完成的描述符。

epoll 只需要将描述符从进程缓冲区向内核缓冲区拷贝一次，并且进程不需要通过轮询来获得事件完成的描述符。
epoll 仅适用于 Linux OS。
epoll 比 select 和 poll 更加灵活而且没有描述符数量限制。
epoll 对多线程编程更有友好，一个线程调用了 epoll_wait() 另一个线程关闭了同一个描述符也不会产生像 select 和 poll 的不确定情况。

工作模式

1. LT 模式（level trigger）
当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。
是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。

2. ET 模式（edge trigger）
和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。
很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。
只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。
